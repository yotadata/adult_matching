# Content ID ãƒªãƒ³ã‚­ãƒ³ã‚°ä»•æ§˜æ›¸

ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿ã¨APIå–å¾—å‹•ç”»ãƒ‡ãƒ¼ã‚¿é–“ã®Content IDç´ã¥ã‘ä»•æ§˜

---

## ðŸ“‹ æ¦‚è¦

### ç›®çš„
- ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿ã®content_idã¨APIå‹•ç”»ãƒ‡ãƒ¼ã‚¿ã®external_idã‚’ç´ã¥ã‘
- ç–‘ä¼¼ãƒ¦ãƒ¼ã‚¶ãƒ¼ç”Ÿæˆæ™‚ã«APIå‹•ç”»ãƒ‡ãƒ¼ã‚¿ã®å­˜åœ¨ã‚’ç¢ºèª
- MLå­¦ç¿’æ™‚ã«ã¯APIå‹•ç”»ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚’ä¿è¨¼

### ãƒ‡ãƒ¼ã‚¿ãƒãƒªã‚·ãƒ¼
```
âœ… APIå‹•ç”»ãƒ‡ãƒ¼ã‚¿ (videos table) â†’ ãƒ¡ã‚¤ãƒ³å‹•ç”»ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹
âŒ ãƒ¬ãƒ“ãƒ¥ãƒ¼å‹•ç”»ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ â†’ ä½¿ç”¨ç¦æ­¢
ðŸ”— Content ID â†’ ä¸¡ãƒ‡ãƒ¼ã‚¿ã®æ©‹æ¸¡ã—å½¹ã®ã¿
```

---

## ðŸ”— Content ID ãƒžãƒƒãƒ”ãƒ³ã‚°

### ãƒ‡ãƒ¼ã‚¿æ§‹é€ 
```python
ContentIDMapping = {
    "review_content_id": "dmm_12345",      # ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿ã®content_id
    "api_external_id": "12345",            # API videosãƒ†ãƒ¼ãƒ–ãƒ«ã®external_id  
    "match_confidence": 0.95,              # ãƒžãƒƒãƒãƒ³ã‚°ä¿¡é ¼åº¦
    "match_method": "exact_id_match",      # ãƒžãƒƒãƒãƒ³ã‚°æ‰‹æ³•
    "api_video_exists": True,              # APIå‹•ç”»ãƒ‡ãƒ¼ã‚¿å­˜åœ¨ãƒ•ãƒ©ã‚°
    "created_at": "2025-09-05T12:00:00Z"
}
```

### ãƒžãƒƒãƒãƒ³ã‚°æˆ¦ç•¥
```python
MATCHING_STRATEGIES = {
    # å„ªå…ˆåº¦1: å®Œå…¨ä¸€è‡´
    "exact_id_match": {
        "method": lambda review_id, api_id: review_id == api_id,
        "confidence": 1.0
    },
    
    # å„ªå…ˆåº¦2: ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹é™¤åŽ»ãƒžãƒƒãƒ
    "prefix_normalized_match": {
        "method": lambda review_id, api_id: 
                 review_id.replace('dmm_', '') == api_id,
        "confidence": 0.9
    },
    
    # å„ªå…ˆåº¦3: ãƒ•ã‚¡ã‚¸ãƒ¼ãƒžãƒƒãƒãƒ³ã‚°
    "fuzzy_match": {
        "method": lambda review_id, api_id: 
                 fuzz.ratio(review_id, api_id) > 85,
        "confidence": 0.8
    }
}
```

---

## ðŸ”„ ãƒªãƒ³ã‚­ãƒ³ã‚°ãƒ—ãƒ­ã‚»ã‚¹

### Step 1: APIå‹•ç”»ãƒ‡ãƒ¼ã‚¿æº–å‚™
```python
def load_api_videos(supabase_client):
    """PostgreSQL videosãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰å…¨å‹•ç”»å–å¾—"""
    response = supabase_client.table('videos').select('external_id, title, genre, maker').execute()
    return {video['external_id']: video for video in response.data}
```

### Step 2: ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿Content IDæŠ½å‡º
```python  
def extract_review_content_ids(review_data):
    """ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰Content IDä¸€è¦§å–å¾—"""
    content_ids = set()
    for review in review_data:
        if 'content_id' in review:
            content_ids.add(review['content_id'])
    return content_ids
```

### Step 3: Content ID ãƒžãƒƒãƒ”ãƒ³ã‚°å®Ÿè¡Œ
```python
def create_content_id_mapping(review_content_ids, api_videos):
    """Content ID ãƒžãƒƒãƒ”ãƒ³ã‚°ä½œæˆ"""
    mappings = []
    
    for review_id in review_content_ids:
        for strategy_name, strategy in MATCHING_STRATEGIES.items():
            for api_id in api_videos.keys():
                if strategy['method'](review_id, api_id):
                    mappings.append({
                        'review_content_id': review_id,
                        'api_external_id': api_id,
                        'match_method': strategy_name,
                        'match_confidence': strategy['confidence'],
                        'api_video_exists': True
                    })
                    break
    
    return mappings
```

### Step 4: æœªãƒžãƒƒãƒãƒ³ã‚°Content IDå‡¦ç†
```python
def handle_unmatched_content_ids(review_content_ids, mappings):
    """APIå‹•ç”»ãƒ‡ãƒ¼ã‚¿ã«å­˜åœ¨ã—ãªã„Content IDã®å‡¦ç†"""
    matched_ids = {m['review_content_id'] for m in mappings}
    unmatched_ids = set(review_content_ids) - matched_ids
    
    # æœªãƒžãƒƒãƒãƒ³ã‚°IDã¯MLå­¦ç¿’ã‹ã‚‰é™¤å¤–
    excluded_mappings = []
    for unmatched_id in unmatched_ids:
        excluded_mappings.append({
            'review_content_id': unmatched_id,
            'api_external_id': None,
            'match_method': None,
            'match_confidence': 0.0,
            'api_video_exists': False,
            'excluded_from_training': True
        })
    
    return excluded_mappings
```

---

## ðŸŽ¯ ç–‘ä¼¼ãƒ¦ãƒ¼ã‚¶ãƒ¼ç”Ÿæˆæ™‚ã®é©ç”¨

### ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å‡¦ç†
```python
class ContentIDFilteredUserGenerator:
    def __init__(self, content_id_mappings):
        self.valid_content_ids = {
            mapping['review_content_id'] 
            for mapping in content_id_mappings 
            if mapping['api_video_exists']
        }
    
    def generate_pseudo_users(self, reviews):
        """APIå‹•ç”»ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ã¿ã§ç–‘ä¼¼ãƒ¦ãƒ¼ã‚¶ãƒ¼ç”Ÿæˆ"""
        filtered_reviews = []
        
        for review in reviews:
            if review['content_id'] in self.valid_content_ids:
                # APIå‹•ç”»ãƒ‡ãƒ¼ã‚¿å­˜åœ¨ç¢ºèªæ¸ˆã¿ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ã¿ä½¿ç”¨
                filtered_reviews.append(review)
        
        return super().generate_pseudo_users(filtered_reviews)
```

### çµ±è¨ˆãƒ¬ãƒãƒ¼ãƒˆ
```python
def generate_linking_report(mappings, total_reviews):
    """Content IDãƒªãƒ³ã‚­ãƒ³ã‚°çµ±è¨ˆãƒ¬ãƒãƒ¼ãƒˆ"""
    return {
        'total_review_content_ids': len(set(m['review_content_id'] for m in mappings)),
        'successfully_linked': len([m for m in mappings if m['api_video_exists']]),
        'linking_success_rate': len([m for m in mappings if m['api_video_exists']]) / len(mappings),
        'excluded_from_training': len([m for m in mappings if not m['api_video_exists']]),
        'confidence_distribution': {
            'high (>0.9)': len([m for m in mappings if m['match_confidence'] > 0.9]),
            'medium (0.8-0.9)': len([m for m in mappings if 0.8 <= m['match_confidence'] <= 0.9]),
            'low (<0.8)': len([m for m in mappings if m['match_confidence'] < 0.8])
        }
    }
```

---

## ðŸ” å“è³ªç®¡ç†

### ãƒžãƒƒãƒãƒ³ã‚°å“è³ªãƒã‚§ãƒƒã‚¯
```python
QUALITY_THRESHOLDS = {
    'min_linking_success_rate': 0.70,      # æœ€ä½Ž70%ã®Content IDãŒãƒªãƒ³ã‚¯æˆåŠŸ
    'min_high_confidence_rate': 0.80,      # 80%ä»¥ä¸ŠãŒé«˜ä¿¡é ¼åº¦ãƒžãƒƒãƒãƒ³ã‚°
    'max_excluded_rate': 0.30               # æœ€å¤§30%ã¾ã§ã®é™¤å¤–ã‚’è¨±å®¹
}

def validate_linking_quality(mappings):
    """ãƒªãƒ³ã‚­ãƒ³ã‚°å“è³ªã®æ¤œè¨¼"""
    report = generate_linking_report(mappings)
    
    checks = {
        'linking_success_rate': report['linking_success_rate'] >= QUALITY_THRESHOLDS['min_linking_success_rate'],
        'high_confidence_rate': (report['confidence_distribution']['high (>0.9)'] / len(mappings)) >= QUALITY_THRESHOLDS['min_high_confidence_rate'],
        'excluded_rate': (report['excluded_from_training'] / len(mappings)) <= QUALITY_THRESHOLDS['max_excluded_rate']
    }
    
    return all(checks.values()), checks
```

### ä¸æ•´åˆæ¤œå‡º
```python
def detect_mapping_inconsistencies(mappings):
    """Content IDãƒžãƒƒãƒ”ãƒ³ã‚°ã®ä¸æ•´åˆæ¤œå‡º"""
    issues = []
    
    # é‡è¤‡ãƒžãƒƒãƒ”ãƒ³ã‚°æ¤œå‡º
    review_ids = [m['review_content_id'] for m in mappings]
    if len(review_ids) != len(set(review_ids)):
        issues.append("Duplicate review content IDs found")
    
    # ä¿¡é ¼åº¦ã¨ãƒžãƒƒãƒãƒ³ã‚°æ‰‹æ³•ã®æ•´åˆæ€§
    for mapping in mappings:
        if mapping['match_method'] == 'exact_id_match' and mapping['match_confidence'] < 1.0:
            issues.append(f"Inconsistent confidence for exact match: {mapping['review_content_id']}")
    
    return issues
```

---

## ðŸ“Š å®Ÿè£…ä¾‹

### å®Œå…¨ãªãƒªãƒ³ã‚­ãƒ³ã‚°ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
```python
def execute_content_id_linking_pipeline():
    """Content IDãƒªãƒ³ã‚­ãƒ³ã‚°å®Œå…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³"""
    
    # Step 1: ãƒ‡ãƒ¼ã‚¿æº–å‚™
    supabase_client = create_supabase_client()
    api_videos = load_api_videos(supabase_client)
    review_data = load_scraped_reviews()
    review_content_ids = extract_review_content_ids(review_data)
    
    # Step 2: ãƒžãƒƒãƒ”ãƒ³ã‚°å®Ÿè¡Œ
    mappings = create_content_id_mapping(review_content_ids, api_videos)
    unmatched_mappings = handle_unmatched_content_ids(review_content_ids, mappings)
    all_mappings = mappings + unmatched_mappings
    
    # Step 3: å“è³ªæ¤œè¨¼
    is_valid, quality_checks = validate_linking_quality(all_mappings)
    if not is_valid:
        raise ValueError(f"Content ID linking quality failed: {quality_checks}")
    
    # Step 4: çµæžœä¿å­˜
    save_content_id_mappings(all_mappings)
    
    # Step 5: ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    report = generate_linking_report(all_mappings)
    return all_mappings, report
```

---

**æ–‡æ›¸ç®¡ç†**  
**æœ€çµ‚æ›´æ–°**: 2025å¹´9æœˆ5æ—¥  
**ç®¡ç†è€…**: Claude Code