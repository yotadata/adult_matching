#!/usr/bin/env python3
"""
åŒ…æ‹¬çš„è¦ä»¶æ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

Backend Refactoring ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®å…¨è¦ä»¶é”æˆã‚’æ¤œè¨¼ã—ã¾ã™ã€‚
"""

import asyncio
import os
import sys
import json
import time
import subprocess
from pathlib import Path
from typing import Dict, List, Any, Tuple
from dataclasses import dataclass, asdict
import logging

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))

@dataclass
class VerificationResult:
    requirement_id: str
    title: str
    status: str  # 'PASS', 'FAIL', 'WARNING', 'SKIP'
    details: List[str]
    metrics: Dict[str, Any]
    duration_ms: float

class ComprehensiveVerifier:
    """åŒ…æ‹¬çš„æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self):
        self.project_root = project_root
        self.results: List[VerificationResult] = []
        self.logger = self._setup_logger()

    def _setup_logger(self) -> logging.Logger:
        """ãƒ­ã‚°è¨­å®š"""
        logger = logging.getLogger('comprehensive_verifier')
        logger.setLevel(logging.INFO)

        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)

        return logger

    async def verify_requirement_1_edge_functions(self) -> VerificationResult:
        """è¦ä»¶1: Edge Functionsçµ±åˆã¨ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã®æ¤œè¨¼"""
        start_time = time.time()
        details = []
        metrics = {}
        status = 'PASS'

        try:
            # Edge Functions ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ç¢ºèª
            functions_dir = self.project_root / 'supabase' / 'functions'

            # 1. çµ±åˆã•ã‚ŒãŸé–¢æ•°ã®å­˜åœ¨ç¢ºèª
            expected_functions = [
                'recommendations/enhanced_two_tower',
                'user-management/likes',
                'user-management/embeddings',
                'user-management/account',
                'content/feed'
            ]

            existing_functions = []
            for func_path in expected_functions:
                func_dir = functions_dir / func_path
                if func_dir.exists() and (func_dir / 'index.ts').exists():
                    existing_functions.append(func_path)
                    details.append(f"âœ… çµ±åˆé–¢æ•°ãŒå­˜åœ¨: {func_path}")
                else:
                    details.append(f"âŒ çµ±åˆé–¢æ•°ãŒä¸åœ¨: {func_path}")
                    status = 'FAIL'

            metrics['integrated_functions_count'] = len(existing_functions)
            metrics['expected_functions_count'] = len(expected_functions)

            # 2. å…±æœ‰ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã®ç¢ºèª
            shared_dir = functions_dir / '_shared'
            shared_modules = ['auth.ts', 'database.ts', 'validation.ts', 'monitoring.ts']

            existing_shared = []
            for module in shared_modules:
                if (shared_dir / module).exists():
                    existing_shared.append(module)
                    details.append(f"âœ… å…±æœ‰ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å­˜åœ¨: {module}")
                else:
                    details.append(f"âš ï¸  å…±æœ‰ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ä¸åœ¨: {module}")
                    if status == 'PASS':
                        status = 'WARNING'

            metrics['shared_modules_count'] = len(existing_shared)

            # 3. TypeScript ãƒ•ã‚¡ã‚¤ãƒ«æ•°ã‚«ã‚¦ãƒ³ãƒˆ
            ts_files = list(functions_dir.rglob('*.ts'))
            metrics['total_ts_files'] = len(ts_files)
            details.append(f"ğŸ“Š TypeScript ãƒ•ã‚¡ã‚¤ãƒ«ç·æ•°: {len(ts_files)}")

        except Exception as e:
            details.append(f"âŒ æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {str(e)}")
            status = 'FAIL'

        duration = (time.time() - start_time) * 1000

        return VerificationResult(
            requirement_id="REQ-1",
            title="Edge Functionsçµ±åˆã¨ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—",
            status=status,
            details=details,
            metrics=metrics,
            duration_ms=duration
        )

    async def verify_requirement_2_ml_pipeline(self) -> VerificationResult:
        """è¦ä»¶2: MLãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ§‹é€ ã®æœ€é©åŒ–æ¤œè¨¼"""
        start_time = time.time()
        details = []
        metrics = {}
        status = 'PASS'

        try:
            ml_dir = self.project_root / 'backend' / 'ml'

            # 1. MLãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ç¢ºèª
            expected_ml_dirs = [
                'models', 'training', 'preprocessing', 'inference', 'evaluation'
            ]

            existing_ml_dirs = []
            for dir_name in expected_ml_dirs:
                if (ml_dir / dir_name).exists():
                    existing_ml_dirs.append(dir_name)
                    details.append(f"âœ… MLãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå­˜åœ¨: {dir_name}")
                else:
                    details.append(f"âŒ MLãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä¸åœ¨: {dir_name}")
                    status = 'FAIL'

            metrics['ml_directories_count'] = len(existing_ml_dirs)

            # 2. Pythonãƒ•ã‚¡ã‚¤ãƒ«æ•°ç¢ºèª
            python_files = list(ml_dir.rglob('*.py'))
            metrics['ml_python_files'] = len(python_files)
            details.append(f"ğŸ“Š MLãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ Python ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(python_files)}")

            # 3. çµ±åˆãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
            tests_dir = self.project_root / 'backend' / 'tests' / 'integration' / 'ml'
            if tests_dir.exists():
                test_files = list(tests_dir.glob('*.py'))
                metrics['ml_test_files'] = len(test_files)
                details.append(f"âœ… MLçµ±åˆãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(test_files)}")
            else:
                details.append("âŒ MLçµ±åˆãƒ†ã‚¹ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒä¸åœ¨")
                status = 'FAIL'

        except Exception as e:
            details.append(f"âŒ æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {str(e)}")
            status = 'FAIL'

        duration = (time.time() - start_time) * 1000

        return VerificationResult(
            requirement_id="REQ-2",
            title="MLãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ§‹é€ ã®æœ€é©åŒ–",
            status=status,
            details=details,
            metrics=metrics,
            duration_ms=duration
        )

    async def verify_requirement_3_data_pipeline(self) -> VerificationResult:
        """è¦ä»¶3: ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³çµ±åˆæ¤œè¨¼"""
        start_time = time.time()
        details = []
        metrics = {}
        status = 'PASS'

        try:
            data_dir = self.project_root / 'backend' / 'data'

            # 1. ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ç¢ºèª
            expected_data_dirs = ['sync', 'processing', 'storage', 'quality']

            existing_data_dirs = []
            for dir_name in expected_data_dirs:
                if (data_dir / dir_name).exists():
                    existing_data_dirs.append(dir_name)
                    details.append(f"âœ… ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå­˜åœ¨: {dir_name}")
                else:
                    details.append(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä¸åœ¨: {dir_name}")
                    status = 'FAIL'

            metrics['data_directories_count'] = len(existing_data_dirs)

            # 2. DMMåŒæœŸã‚¹ã‚¯ãƒªãƒ—ãƒˆç¢ºèª
            dmm_sync_dir = data_dir / 'sync' / 'dmm'
            if dmm_sync_dir.exists():
                dmm_files = list(dmm_sync_dir.glob('*.py'))
                metrics['dmm_sync_files'] = len(dmm_files)
                details.append(f"âœ… DMMåŒæœŸãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(dmm_files)}")
            else:
                details.append("âŒ DMMåŒæœŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒä¸åœ¨")
                status = 'FAIL'

        except Exception as e:
            details.append(f"âŒ æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {str(e)}")
            status = 'FAIL'

        duration = (time.time() - start_time) * 1000

        return VerificationResult(
            requirement_id="REQ-3",
            title="ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³çµ±åˆ",
            status=status,
            details=details,
            metrics=metrics,
            duration_ms=duration
        )

    async def verify_requirement_4_directory_structure(self) -> VerificationResult:
        """è¦ä»¶4: ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã®åˆç†åŒ–æ¤œè¨¼"""
        start_time = time.time()
        details = []
        metrics = {}
        status = 'PASS'

        try:
            # 1. ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ä¸»è¦ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç¢ºèª
            backend_dir = self.project_root / 'backend'
            expected_backend_dirs = [
                'ml', 'data', 'monitoring', 'optimization', 'tests', 'scripts'
            ]

            existing_backend_dirs = []
            for dir_name in expected_backend_dirs:
                if (backend_dir / dir_name).exists():
                    existing_backend_dirs.append(dir_name)
                    details.append(f"âœ… ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå­˜åœ¨: {dir_name}")
                else:
                    details.append(f"âŒ ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä¸åœ¨: {dir_name}")
                    status = 'FAIL'

            metrics['backend_directories_count'] = len(existing_backend_dirs)

            # 2. ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ãƒ»ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
            temp_patterns = ['*.pyc', '__pycache__', '*.tmp', '.DS_Store']
            temp_files_count = 0

            for pattern in temp_patterns:
                temp_files = list(self.project_root.rglob(pattern))
                # .venv ã¨ node_modules ã¯é™¤å¤–
                filtered_files = [
                    f for f in temp_files
                    if '.venv' not in str(f) and 'node_modules' not in str(f)
                ]
                temp_files_count += len(filtered_files)

            metrics['temp_files_count'] = temp_files_count

            if temp_files_count == 0:
                details.append("âœ… ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—æ¸ˆã¿")
            else:
                details.append(f"âš ï¸  ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ®‹å­˜: {temp_files_count}å€‹")
                if status == 'PASS':
                    status = 'WARNING'

        except Exception as e:
            details.append(f"âŒ æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {str(e)}")
            status = 'FAIL'

        duration = (time.time() - start_time) * 1000

        return VerificationResult(
            requirement_id="REQ-4",
            title="ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã®åˆç†åŒ–",
            status=status,
            details=details,
            metrics=metrics,
            duration_ms=duration
        )

    async def verify_requirement_5_testing(self) -> VerificationResult:
        """è¦ä»¶5: åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒ†ã‚£ãƒ³ã‚°çµ±åˆæ¤œè¨¼"""
        start_time = time.time()
        details = []
        metrics = {}
        status = 'PASS'

        try:
            tests_dir = self.project_root / 'backend' / 'tests'

            # 1. ãƒ†ã‚¹ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ç¢ºèª
            expected_test_dirs = ['unit', 'integration', 'e2e']

            existing_test_dirs = []
            for dir_name in expected_test_dirs:
                if (tests_dir / dir_name).exists():
                    existing_test_dirs.append(dir_name)
                    details.append(f"âœ… ãƒ†ã‚¹ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå­˜åœ¨: {dir_name}")
                else:
                    details.append(f"âŒ ãƒ†ã‚¹ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä¸åœ¨: {dir_name}")
                    status = 'FAIL'

            metrics['test_directories_count'] = len(existing_test_dirs)

            # 2. ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«æ•°ç¢ºèª
            total_test_files = 0
            for test_type in expected_test_dirs:
                test_type_dir = tests_dir / test_type
                if test_type_dir.exists():
                    test_files = list(test_type_dir.rglob('test_*.py'))
                    metrics[f'{test_type}_test_files'] = len(test_files)
                    total_test_files += len(test_files)
                    details.append(f"ğŸ“Š {test_type}ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(test_files)}")

            metrics['total_test_files'] = total_test_files

            # 3. çµ±åˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„APIãƒ†ã‚¹ãƒˆç¢ºèª
            content_tests_dir = tests_dir / 'integration' / 'content'
            if content_tests_dir.exists():
                content_test_files = list(content_tests_dir.glob('test_*.py'))
                metrics['content_api_test_files'] = len(content_test_files)
                details.append(f"âœ… çµ±åˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„APIãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(content_test_files)}")
            else:
                details.append("âŒ çµ±åˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„APIãƒ†ã‚¹ãƒˆãŒä¸åœ¨")
                status = 'FAIL'

        except Exception as e:
            details.append(f"âŒ æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {str(e)}")
            status = 'FAIL'

        duration = (time.time() - start_time) * 1000

        return VerificationResult(
            requirement_id="REQ-5",
            title="åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒ†ã‚£ãƒ³ã‚°çµ±åˆ",
            status=status,
            details=details,
            metrics=metrics,
            duration_ms=duration
        )

    async def verify_non_functional_requirements(self) -> VerificationResult:
        """éæ©Ÿèƒ½è¦ä»¶ã®æ¤œè¨¼"""
        start_time = time.time()
        details = []
        metrics = {}
        status = 'PASS'

        try:
            # 1. ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç¢ºèª
            docs_to_check = [
                'backend/README.md',
                'docs/backend-architecture.md',
                'docs/developer-onboarding.md'
            ]

            docs_existing = 0
            for doc_path in docs_to_check:
                full_path = self.project_root / doc_path
                if full_path.exists():
                    docs_existing += 1
                    details.append(f"âœ… ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå­˜åœ¨: {doc_path}")
                else:
                    details.append(f"âŒ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä¸åœ¨: {doc_path}")
                    status = 'FAIL'

            metrics['documentation_files'] = docs_existing

            # 2. SQLãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
            migrations_dir = self.project_root / 'supabase' / 'migrations'
            if migrations_dir.exists():
                migration_files = list(migrations_dir.glob('*.sql'))
                metrics['migration_files'] = len(migration_files)
                details.append(f"âœ… SQLãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(migration_files)}")
            else:
                details.append("âŒ ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒä¸åœ¨")
                status = 'FAIL'

            # 3. ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ç¢ºèª
            monitoring_dir = self.project_root / 'backend' / 'monitoring'
            if monitoring_dir.exists():
                monitoring_files = list(monitoring_dir.glob('*.py'))
                metrics['monitoring_files'] = len(monitoring_files)
                details.append(f"âœ… ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(monitoring_files)}")
            else:
                details.append("âŒ ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒä¸åœ¨")
                status = 'FAIL'

        except Exception as e:
            details.append(f"âŒ æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {str(e)}")
            status = 'FAIL'

        duration = (time.time() - start_time) * 1000

        return VerificationResult(
            requirement_id="NFR",
            title="éæ©Ÿèƒ½è¦ä»¶",
            status=status,
            details=details,
            metrics=metrics,
            duration_ms=duration
        )

    async def run_comprehensive_verification(self) -> Dict[str, Any]:
        """åŒ…æ‹¬çš„æ¤œè¨¼ã®å®Ÿè¡Œ"""
        self.logger.info("ğŸ” åŒ…æ‹¬çš„è¦ä»¶æ¤œè¨¼ã‚’é–‹å§‹ã—ã¾ã™...")

        # å…¨æ¤œè¨¼ã‚’ä¸¦åˆ—å®Ÿè¡Œ
        verification_tasks = [
            self.verify_requirement_1_edge_functions(),
            self.verify_requirement_2_ml_pipeline(),
            self.verify_requirement_3_data_pipeline(),
            self.verify_requirement_4_directory_structure(),
            self.verify_requirement_5_testing(),
            self.verify_non_functional_requirements()
        ]

        self.results = await asyncio.gather(*verification_tasks)

        # çµæœé›†è¨ˆ
        total_requirements = len(self.results)
        passed_requirements = len([r for r in self.results if r.status == 'PASS'])
        failed_requirements = len([r for r in self.results if r.status == 'FAIL'])
        warning_requirements = len([r for r in self.results if r.status == 'WARNING'])

        overall_status = 'PASS'
        if failed_requirements > 0:
            overall_status = 'FAIL'
        elif warning_requirements > 0:
            overall_status = 'WARNING'

        summary = {
            'overall_status': overall_status,
            'total_requirements': total_requirements,
            'passed_requirements': passed_requirements,
            'failed_requirements': failed_requirements,
            'warning_requirements': warning_requirements,
            'success_rate': (passed_requirements / total_requirements) * 100,
            'total_duration_ms': sum(r.duration_ms for r in self.results),
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
            'results': [asdict(result) for result in self.results]
        }

        return summary

    def generate_verification_report(self, summary: Dict[str, Any]) -> str:
        """æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ"""
        overall_emoji = {
            'PASS': 'âœ…',
            'WARNING': 'âš ï¸',
            'FAIL': 'âŒ'
        }[summary['overall_status']]

        report = f"""
# ğŸ” Backend Refactoring åŒ…æ‹¬çš„è¦ä»¶æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆ

## ğŸ“Š æ¤œè¨¼ã‚µãƒãƒªãƒ¼

**å…¨ä½“ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹**: {overall_emoji} {summary['overall_status']}
**æˆåŠŸç‡**: {summary['success_rate']:.1f}% ({summary['passed_requirements']}/{summary['total_requirements']})
**æ¤œè¨¼æ™‚é–“**: {summary['total_duration_ms']:.0f}ms
**å®Ÿè¡Œæ—¥æ™‚**: {summary['timestamp']}

### è¦ä»¶åˆ¥çµæœ

| è¦ä»¶ID | ã‚¿ã‚¤ãƒˆãƒ« | ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ | å®Ÿè¡Œæ™‚é–“ |
|--------|----------|-----------|----------|
"""

        for result in self.results:
            status_emoji = {
                'PASS': 'âœ…',
                'WARNING': 'âš ï¸',
                'FAIL': 'âŒ'
            }[result.status]

            report += f"| {result.requirement_id} | {result.title} | {status_emoji} {result.status} | {result.duration_ms:.0f}ms |\n"

        report += "\n## ğŸ“‹ è©³ç´°çµæœ\n\n"

        for result in self.results:
            report += f"### {result.requirement_id}: {result.title}\n\n"
            report += f"**ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹**: {result.status}\n\n"

            if result.details:
                report += "**è©³ç´°**:\n"
                for detail in result.details:
                    report += f"- {detail}\n"
                report += "\n"

            if result.metrics:
                report += "**ãƒ¡ãƒˆãƒªã‚¯ã‚¹**:\n"
                for key, value in result.metrics.items():
                    report += f"- {key}: {value}\n"
                report += "\n"

        report += f"""
## ğŸ¯ æ¤œè¨¼çµè«–

ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®è¦ä»¶æ¤œè¨¼ãŒå®Œäº†ã—ã¾ã—ãŸã€‚

### ğŸ† æˆæœ
- **å®Ÿè£…è¦ä»¶**: {summary['passed_requirements']}/{summary['total_requirements']} é”æˆ
- **æˆåŠŸç‡**: {summary['success_rate']:.1f}%
- **ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹**: {summary['overall_status']}

### ğŸ“ˆ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—
{"âœ… å…¨è¦ä»¶é”æˆã«ã‚ˆã‚Šæœ¬ç•ªãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆæº–å‚™å®Œäº†" if summary['overall_status'] == 'PASS' else "âš ï¸  è­¦å‘Šã¾ãŸã¯ã‚¨ãƒ©ãƒ¼ã®è§£æ±ºãŒå¿…è¦"}

---
**Generated by**: Comprehensive Verification System
**Version**: 1.0
**Report Type**: Backend Refactoring Requirements Verification
"""

        return report

async def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    verifier = ComprehensiveVerifier()

    try:
        # åŒ…æ‹¬çš„æ¤œè¨¼å®Ÿè¡Œ
        summary = await verifier.run_comprehensive_verification()

        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        report = verifier.generate_verification_report(summary)

        # ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›
        print(report)

        # ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        report_dir = verifier.project_root / 'backend' / 'reports'
        report_dir.mkdir(exist_ok=True)

        report_file = report_dir / 'comprehensive_verification_report.md'
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)

        print(f"\nğŸ“„ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ: {report_file}")

        # çµæœã«åŸºã¥ãçµ‚äº†ã‚³ãƒ¼ãƒ‰
        exit_code = 0 if summary['overall_status'] == 'PASS' else 1
        sys.exit(exit_code)

    except Exception as e:
        print(f"âŒ æ¤œè¨¼ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main())