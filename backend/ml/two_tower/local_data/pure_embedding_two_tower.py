#!/usr/bin/env python3
"""
å®Œå…¨åŸ‹ã‚è¾¼ã¿å­¦ç¿’ç‰ˆTwo-Towerãƒ¢ãƒ‡ãƒ«
ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ»å‹•ç”»ã¨ã‚‚ã«æ‰‹å‹•ç‰¹å¾´é‡ãªã—ã€ç´”ç²‹ãªåŸ‹ã‚è¾¼ã¿å­¦ç¿’
"""

import os
import json
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models, optimizers, regularizers
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score
import pickle
from pathlib import Path
from data_loader import SupabaseDataLoader

class PureEmbeddingTwoTowerModel:
    """å®Œå…¨åŸ‹ã‚è¾¼ã¿å­¦ç¿’ç‰ˆTwo-Towerãƒ¢ãƒ‡ãƒ«ï¼ˆæ‰‹å‹•ç‰¹å¾´é‡ãªã—ï¼‰"""

    def __init__(self, num_videos=3742, embed_dim=256, final_embed_dim=768):
        self.num_videos = num_videos
        self.embed_dim = embed_dim  # å‹•ç”»åŸ‹ã‚è¾¼ã¿æ¬¡å…ƒï¼ˆå¤§ããè¨­å®šï¼‰
        self.final_embed_dim = final_embed_dim
        self.output_dir = Path("models")
        self.output_dir.mkdir(exist_ok=True)

        # ãƒ¢ãƒ‡ãƒ«
        self.video_embedding = None
        self.user_tower = None
        self.item_tower = None
        self.full_model = None

        # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼
        self.data_loader = SupabaseDataLoader()

    def build_video_embedding_layer(self):
        """å¤§å®¹é‡å‹•ç”»åŸ‹ã‚è¾¼ã¿å±¤ï¼ˆé‡ãŸã„ãƒ¢ãƒ‡ãƒ«OKï¼‰"""
        self.video_embedding = layers.Embedding(
            input_dim=self.num_videos + 1,  # +1 for unknown videos
            output_dim=self.embed_dim,      # 256æ¬¡å…ƒï¼ˆå¤§ãã‚ï¼‰
            embeddings_regularizer=regularizers.L2(0.001),  # æ­£å‰‡åŒ–
            mask_zero=True,
            name='video_embedding'
        )

    def build_user_tower(self, max_history=100):
        """LIKE/NOPEå±¥æ­´ã‹ã‚‰ãƒ¦ãƒ¼ã‚¶ãƒ¼åŸ‹ã‚è¾¼ã¿ï¼ˆé‡ãŸã„ãƒ¢ãƒ‡ãƒ«ï¼‰"""
        # LIKEå±¥æ­´å…¥åŠ›ï¼ˆé•·ã„å±¥æ­´ã«å¯¾å¿œï¼‰
        like_history_input = layers.Input(shape=(max_history,), name='like_history')
        like_embeds = self.video_embedding(like_history_input)
        like_mask = layers.Masking(mask_value=0.0)(like_embeds)

        # LIKEå±¥æ­´ã‚’LSTMã§å‡¦ç†ï¼ˆé †åºã‚‚è€ƒæ…®ï¼‰
        like_lstm = layers.LSTM(512, dropout=0.2, recurrent_dropout=0.2, return_sequences=True)(like_mask)
        like_attention = layers.GlobalAveragePooling1D()(like_lstm)

        # NOPEå±¥æ­´å…¥åŠ›
        nope_history_input = layers.Input(shape=(max_history,), name='nope_history')
        nope_embeds = self.video_embedding(nope_history_input)
        nope_mask = layers.Masking(mask_value=0.0)(nope_embeds)

        # NOPEå±¥æ­´ã‚‚LSTMã§å‡¦ç†
        nope_lstm = layers.LSTM(512, dropout=0.2, recurrent_dropout=0.2, return_sequences=True)(nope_mask)
        nope_attention = layers.GlobalAveragePooling1D()(nope_lstm)

        # LIKE/NOPEé‡ã¿ä»˜ãçµåˆï¼ˆLIKE: +1.0, NOPE: -0.6ï¼‰
        weighted_user_repr = layers.Add()([
            layers.Lambda(lambda x: x * 1.0)(like_attention),
            layers.Lambda(lambda x: x * -0.6)(nope_attention)
        ])

        # æ·±ã„ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¿ãƒ¯ãƒ¼ï¼ˆé‡ãŸã„ãƒ¢ãƒ‡ãƒ«OKï¼‰
        user_dense1 = layers.Dense(1024, activation='relu',
                                  kernel_regularizer=regularizers.L2(0.001))(weighted_user_repr)
        user_dropout1 = layers.Dropout(0.4)(user_dense1)

        user_dense2 = layers.Dense(512, activation='relu',
                                  kernel_regularizer=regularizers.L2(0.001))(user_dropout1)
        user_dropout2 = layers.Dropout(0.3)(user_dense2)

        user_dense3 = layers.Dense(256, activation='relu',
                                  kernel_regularizer=regularizers.L2(0.001))(user_dropout2)
        user_dropout3 = layers.Dropout(0.2)(user_dense3)

        # æœ€çµ‚ãƒ¦ãƒ¼ã‚¶ãƒ¼åŸ‹ã‚è¾¼ã¿
        user_embedding = layers.Dense(self.final_embed_dim, name='user_embedding_dense')(user_dropout3)
        user_embedding_norm = layers.Lambda(lambda x: tf.nn.l2_normalize(x, axis=1),
                                           name='user_embedding')(user_embedding)

        self.user_tower = models.Model(
            inputs=[like_history_input, nope_history_input],
            outputs=user_embedding_norm,
            name='pure_embedding_user_tower'
        )

    def build_item_tower(self):
        """ç´”ç²‹å‹•ç”»åŸ‹ã‚è¾¼ã¿ãƒ™ãƒ¼ã‚¹ã®ã‚¢ã‚¤ãƒ†ãƒ ã‚¿ãƒ¯ãƒ¼ï¼ˆé‡ãŸã„ãƒ¢ãƒ‡ãƒ«ï¼‰"""
        # å‹•ç”»IDå…¥åŠ›ã®ã¿ï¼ˆç‰¹å¾´é‡ãªã—ï¼‰
        item_id_input = layers.Input(shape=(1,), name='item_id')
        item_embed = layers.Flatten()(self.video_embedding(item_id_input))

        # æ·±ã„ã‚¢ã‚¤ãƒ†ãƒ ã‚¿ãƒ¯ãƒ¼ï¼ˆå‹•ç”»åŸ‹ã‚è¾¼ã¿ã‹ã‚‰è±Šå¯Œãªè¡¨ç¾ã‚’å­¦ç¿’ï¼‰
        item_dense1 = layers.Dense(1024, activation='relu',
                                  kernel_regularizer=regularizers.L2(0.001))(item_embed)
        item_dropout1 = layers.Dropout(0.4)(item_dense1)

        item_dense2 = layers.Dense(512, activation='relu',
                                  kernel_regularizer=regularizers.L2(0.001))(item_dropout1)
        item_dropout2 = layers.Dropout(0.3)(item_dense2)

        item_dense3 = layers.Dense(256, activation='relu',
                                  kernel_regularizer=regularizers.L2(0.001))(item_dropout2)
        item_dropout3 = layers.Dropout(0.2)(item_dense3)

        item_dense4 = layers.Dense(128, activation='relu',
                                  kernel_regularizer=regularizers.L2(0.001))(item_dropout3)
        item_dropout4 = layers.Dropout(0.1)(item_dense4)

        # æœ€çµ‚ã‚¢ã‚¤ãƒ†ãƒ åŸ‹ã‚è¾¼ã¿
        item_embedding = layers.Dense(self.final_embed_dim, name='item_embedding_dense')(item_dropout4)
        item_embedding_norm = layers.Lambda(lambda x: tf.nn.l2_normalize(x, axis=1),
                                           name='item_embedding')(item_embedding)

        self.item_tower = models.Model(
            inputs=item_id_input,
            outputs=item_embedding_norm,
            name='pure_embedding_item_tower'
        )

    def build_full_model(self, max_history=100):
        """å®Œå…¨åŸ‹ã‚è¾¼ã¿å­¦ç¿’Two-Towerãƒ¢ãƒ‡ãƒ«"""

        # å‹•ç”»åŸ‹ã‚è¾¼ã¿å±¤æ§‹ç¯‰
        self.build_video_embedding_layer()

        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ»ã‚¢ã‚¤ãƒ†ãƒ ã‚¿ãƒ¯ãƒ¼æ§‹ç¯‰
        self.build_user_tower(max_history)
        self.build_item_tower()

        # å…¥åŠ›ï¼ˆå‹•ç”»ç‰¹å¾´é‡ãªã—ï¼‰
        like_history_input = layers.Input(shape=(max_history,), name='like_history')
        nope_history_input = layers.Input(shape=(max_history,), name='nope_history')
        item_id_input = layers.Input(shape=(1,), name='item_id')

        # åŸ‹ã‚è¾¼ã¿è¨ˆç®—
        user_embedding = self.user_tower([like_history_input, nope_history_input])
        item_embedding = self.item_tower(item_id_input)

        # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦è¨ˆç®—
        similarity = layers.Dot(axes=1, normalize=False, name='similarity')([user_embedding, item_embedding])

        # æœ€çµ‚äºˆæ¸¬ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ãªã‚·ã‚°ãƒ¢ã‚¤ãƒ‰ï¼‰
        prediction = layers.Dense(1, activation='sigmoid', name='prediction')(similarity)

        # ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰
        self.full_model = models.Model(
            inputs=[like_history_input, nope_history_input, item_id_input],
            outputs=prediction,
            name='pure_embedding_two_tower_full'
        )

        return self.full_model

    def prepare_training_data(self, samples, data_loader, max_history=100):
        """å®Œå…¨åŸ‹ã‚è¾¼ã¿å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿æº–å‚™ï¼ˆå‹•ç”»ç‰¹å¾´é‡ãªã—ï¼‰"""
        like_histories = []
        nope_histories = []
        item_ids = []
        labels = []

        # å‹•ç”»IDãƒãƒƒãƒ”ãƒ³ã‚°ä½œæˆ
        video_ids = data_loader.videos_df['id'].unique()
        video_id_to_idx = {vid: idx+1 for idx, vid in enumerate(video_ids)}  # 0ã¯äºˆç´„

        print(f"ğŸ“Š Video ID mapping: {len(video_id_to_idx)} videos")

        for sample in samples:
            # LIKEå±¥æ­´ã‚’é•·ã‚ã«å¯¾å¿œï¼ˆ100ä»¶ã¾ã§ï¼‰
            like_hist = [video_id_to_idx.get(vid, 0) for vid in sample['user_like_history']]
            like_hist = like_hist[-max_history:] if len(like_hist) > max_history else like_hist
            like_hist += [0] * (max_history - len(like_hist))

            # NOPEå±¥æ­´ã‚’é•·ã‚ã«å¯¾å¿œ
            nope_hist = [video_id_to_idx.get(vid, 0) for vid in sample['user_nope_history']]
            nope_hist = nope_hist[-max_history:] if len(nope_hist) > max_history else nope_hist
            nope_hist += [0] * (max_history - len(nope_hist))

            # å‹•ç”»IDã®ã¿ï¼ˆç‰¹å¾´é‡ãªã—ï¼‰
            item_id = video_id_to_idx.get(sample['video_id'], 0)

            like_histories.append(like_hist)
            nope_histories.append(nope_hist)
            item_ids.append([item_id])
            labels.append(sample['label'])

        return {
            'like_histories': np.array(like_histories),
            'nope_histories': np.array(nope_histories),
            'item_ids': np.array(item_ids),
            'labels': np.array(labels),
            'video_id_mapping': video_id_to_idx
        }

    def train(self, data_loader: SupabaseDataLoader):
        """å®Œå…¨åŸ‹ã‚è¾¼ã¿å­¦ç¿’ç‰ˆãƒ¢ãƒ‡ãƒ«å­¦ç¿’"""
        print("ğŸš€ Starting Pure Embedding Two-Tower training...")

        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        data_loader.load_all_data()
        training_samples = data_loader.get_realtime_training_data()

        # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿æº–å‚™ï¼ˆå‹•ç”»ç‰¹å¾´é‡ãªã—ï¼‰
        data = self.prepare_training_data(training_samples, data_loader, max_history=100)

        print(f"ğŸ“Š Pure Embedding training features:")
        print(f"   Like histories shape: {data['like_histories'].shape}")
        print(f"   Nope histories shape: {data['nope_histories'].shape}")
        print(f"   Item IDs shape: {data['item_ids'].shape}")
        print(f"   Labels shape: {data['labels'].shape}")
        print(f"   No manual features! Pure embedding learning.")

        # ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ï¼ˆé‡ãŸã„ãƒ¢ãƒ‡ãƒ«ï¼‰
        self.full_model = self.build_full_model(max_history=100)

        print(f"\nğŸ“‹ Pure Embedding Model Architecture:")
        self.full_model.summary()

        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°è¡¨ç¤º
        total_params = self.full_model.count_params()
        print(f"ğŸ§  Total parameters: {total_params:,} ({total_params/1e6:.1f}M)")

        # ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«
        self.full_model.compile(
            optimizer=optimizers.Adam(learning_rate=0.0005),  # å°‘ã—å°ã•ã‚å­¦ç¿’ç‡
            loss='binary_crossentropy',
            metrics=['accuracy', 'precision', 'recall']
        )

        # ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
        indices = np.arange(len(data['labels']))
        train_idx, val_idx = train_test_split(indices, test_size=0.2, random_state=42, stratify=data['labels'])

        train_data = {
            'like_histories': data['like_histories'][train_idx],
            'nope_histories': data['nope_histories'][train_idx],
            'item_ids': data['item_ids'][train_idx],
            'labels': data['labels'][train_idx]
        }

        val_data = {
            'like_histories': data['like_histories'][val_idx],
            'nope_histories': data['nope_histories'][val_idx],
            'item_ids': data['item_ids'][val_idx],
            'labels': data['labels'][val_idx]
        }

        print(f"ğŸ‹ï¸ Training pure embedding model...")
        print(f"   Training samples: {len(train_data['labels'])}")
        print(f"   Validation samples: {len(val_data['labels'])}")

        # å­¦ç¿’å®Ÿè¡Œï¼ˆé‡ã„ãƒ¢ãƒ‡ãƒ«ãªã®ã§ã‚¨ãƒãƒƒã‚¯æ•°èª¿æ•´ï¼‰
        history = self.full_model.fit(
            x=[train_data['like_histories'], train_data['nope_histories'], train_data['item_ids']],
            y=train_data['labels'],
            epochs=30,  # æ—©æœŸåœæ­¢ãŒã‚ã‚‹ã®ã§å¤šã‚ã«è¨­å®š
            batch_size=16,  # ãƒãƒƒãƒã‚µã‚¤ã‚ºå°ã•ã‚
            validation_data=(
                [val_data['like_histories'], val_data['nope_histories'], val_data['item_ids']],
                val_data['labels']
            ),
            verbose=1,
            callbacks=[
                ModelCheckpoint(
                    filepath=str(self.output_dir / "pure_embedding_best.keras"),
                    monitor='val_accuracy',
                    save_best_only=True,
                    save_weights_only=False,
                    mode='max',
                    verbose=1
                ),
                EarlyStopping(
                    monitor='val_accuracy',
                    patience=5,
                    mode='max',
                    verbose=1,
                    restore_best_weights=True
                ),
                ReduceLROnPlateau(
                    monitor='val_loss',
                    factor=0.5,
                    patience=3,
                    min_lr=1e-6,
                    verbose=1
                )
            ]
        )

        # è©•ä¾¡
        val_predictions = self.full_model.predict([
            val_data['like_histories'], val_data['nope_histories'], val_data['item_ids']
        ])
        val_predictions_binary = (val_predictions > 0.5).astype(int).flatten()

        accuracy = accuracy_score(val_data['labels'], val_predictions_binary)
        precision = precision_score(val_data['labels'], val_predictions_binary)
        recall = recall_score(val_data['labels'], val_predictions_binary)
        f1 = f1_score(val_data['labels'], val_predictions_binary)

        print(f"\nâœ… Pure Embedding Validation Results:")
        print(f"   - Accuracy: {accuracy:.4f}")
        print(f"   - Precision: {precision:.4f}")
        print(f"   - Recall: {recall:.4f}")
        print(f"   - F1-Score: {f1:.4f}")

        # å‹•ç”»IDãƒãƒƒãƒ”ãƒ³ã‚°ä¿å­˜
        self.video_id_mapping = data['video_id_mapping']

        return history

    def save_models(self):
        """å®Œå…¨åŸ‹ã‚è¾¼ã¿å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ä¿å­˜"""
        print("ğŸ’¾ Saving pure embedding models...")

        # Keraså½¢å¼ã§ä¿å­˜
        self.user_tower.save(self.output_dir / "user_tower_768.keras")
        self.item_tower.save(self.output_dir / "item_tower_768.keras")
        self.full_model.save(self.output_dir / "full_model_768.keras")

        # å‹•ç”»åŸ‹ã‚è¾¼ã¿å±¤ã‚’å˜ç‹¬ã§ä¿å­˜
        video_embedding_input = layers.Input(shape=(1,), name='video_input')
        video_embedding_output = layers.Flatten()(self.video_embedding(video_embedding_input))
        video_embedding_model = models.Model(
            inputs=video_embedding_input,
            outputs=video_embedding_output,
            name='video_embedding_model'
        )
        video_embedding_model.save(self.output_dir / "video_embedding_768.keras")

        # å‹•ç”»IDãƒãƒƒãƒ”ãƒ³ã‚°ä¿å­˜
        with open(self.output_dir / "video_id_mapping.pkl", 'wb') as f:
            pickle.dump(self.video_id_mapping, f)

        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜
        metadata = {
            "model_type": "pure_embedding_two_tower",
            "embedding_dim": self.final_embed_dim,
            "video_embed_dim": self.embed_dim,
            "num_videos": self.num_videos,
            "model_version": "4.0_pure_embedding",
            "created_at": "2025-09-28T01:00:00.000000",
            "features": {
                "manual_features": False,
                "pure_embedding": True,
                "like_history_max": 100,
                "nope_history_max": 100,
                "lstm_enabled": True,
                "attention_enabled": True
            },
            "performance": {
                "heavy_model": True,
                "backend_optimized": True,
                "realtime_inference": True
            }
        }

        with open(self.output_dir / "metadata.json", "w") as f:
            json.dump(metadata, f, indent=2)

        print(f"âœ… Pure embedding models saved to: {self.output_dir}")
        print(f"   ğŸ“ User tower: LIKE/NOPEå±¥æ­´ â†’ LSTM â†’ æ·±å±¤NN")
        print(f"   ğŸ“ Item tower: å‹•ç”»ID â†’ å¤§å®¹é‡åŸ‹ã‚è¾¼ã¿ â†’ æ·±å±¤NN")
        print(f"   ğŸ“ Video embedding: {self.num_videos}å‹•ç”» Ã— {self.embed_dim}æ¬¡å…ƒ")
        print(f"   ğŸ“ No manual features - Pure embedding learning!")

if __name__ == "__main__":
    print("ğŸš€ Pure Embedding Two-Tower training starting...")

    # å®Œå…¨åŸ‹ã‚è¾¼ã¿å­¦ç¿’Two-Towerå®Ÿè¡Œ
    model = PureEmbeddingTwoTowerModel(
        num_videos=3742,
        embed_dim=256,      # å¤§å®¹é‡åŸ‹ã‚è¾¼ã¿
        final_embed_dim=768
    )
    loader = SupabaseDataLoader()

    try:
        # å­¦ç¿’å®Ÿè¡Œ
        history = model.train(loader)

        # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
        if model.user_tower is not None and model.item_tower is not None:
            model.save_models()
            print(f"\nğŸ‰ Pure Embedding Two-Tower training completed!")
            print(f"ğŸš€ Ready for pure embedding-based recommendations!")
            print(f"ğŸ’ª Heavy model optimized for backend processing!")
        else:
            print("âŒ Models not trained properly")
    except Exception as e:
        print(f"âŒ Error during training: {e}")
        import traceback
        traceback.print_exc()